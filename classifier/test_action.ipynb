{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('venv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "092ed8abd312cbab0a98b75895a1e9c0250270ee5380f9df4b1b91829554bc4e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in encoder and model\n",
    "from joblib import load\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_data():\n",
    "    ''' Load in the pretrained model & label encoders.\n",
    "    '''\n",
    "    d = load(\"label_encoder.joblib.dat\")\n",
    "    d_classes = load(\"encoder_classes.joblib.dat\")\n",
    "    dialect_classifier = load(\"dialect_classifier.joblib.dat\")\n",
    "    test_case = load(\"test_case.joblib.dat\")\n",
    "\n",
    "    # remove target class from test data\n",
    "    del test_case[\"class_target\"]\n",
    "\n",
    "    # update the classes for each of our label encoders\n",
    "    for key,item in d.items():\n",
    "        d[key]._classes = d_classes[key]\n",
    "\n",
    "    return d, d_classes, dialect_classifier, test_case\n",
    "\n",
    "def encode_data(input_data):\n",
    "    ''' Encode our input data with pre-trained label encoders.\n",
    "    '''\n",
    "    # encode our test data\n",
    "    test_case_encoded = input_data\n",
    "\n",
    "    for i, row in input_data.items():\n",
    "        test_case_encoded[i] = d[i].transform([input_data[i]])\n",
    "\n",
    "    test_case_encoded = test_case_encoded.apply(lambda x:x[0])\n",
    "\n",
    "    return test_case_encoded\n",
    "\n",
    "def predict_cities(test_case_encoded):\n",
    "    ''' Take in encoded data & return top three predicted cities.\n",
    "    '''\n",
    "    # convert input data to DMatrix format\n",
    "    test_case_encoded_d = xgb.DMatrix(test_case_encoded.values.reshape((1,-1)))\n",
    "    test_case_encoded_d.feature_names =  test_case_encoded.index.tolist()\n",
    "\n",
    "    # classify using our pre-trained model\n",
    "    predictions = dialect_classifier.predict(test_case_encoded_d)\n",
    "\n",
    "    # return the top 3 classes\n",
    "    top_3 = np.argsort(predictions, axis=1)[ : ,-3 : ]\n",
    "\n",
    "    cities = d[\"class_target\"].inverse_transform(top_3[0].tolist())\n",
    "\n",
    "    return cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del test_case[\"class_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'# update the classes for each of our label encoders\\nfor key,item in d.items():\\n    d[key]._classes=d_classes[key]\\n# encode our test data   \\ntest_case_encoded=test_case \\nfor i,row in test_case.items():\\n    test_case_encoded[i]=d[i].transform([test_case[i]])\\ntest_case_encoded=test_case_encoded.apply(lambda x:x[0])    \\n'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "\"\"\"# update the classes for each of our label encoders\n",
    "for key,item in d.items():\n",
    "    d[key]._classes=d_classes[key]\n",
    "# encode our test data   \n",
    "test_case_encoded=test_case \n",
    "for i,row in test_case.items():\n",
    "    test_case_encoded[i]=d[i].transform([test_case[i]])\n",
    "test_case_encoded=test_case_encoded.apply(lambda x:x[0])    \n",
    "\"\"\"   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'#convert input data to DMatrix fromat\\ntest_case_encoded_d=xgb.DMatrix(test_case_encoded.values.reshape((1,-1)))\\ntest_case_encoded_d.feature_names=test_case_encoded.index.tolist()\\n# classify using our pre-trained model\\npredictions=dialect_classifier.predict(test_case_encoded_d)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "\"\"\"#convert input data to DMatrix fromat\n",
    "test_case_encoded_d=xgb.DMatrix(test_case_encoded.values.reshape((1,-1)))\n",
    "test_case_encoded_d.feature_names=test_case_encoded.index.tolist()\n",
    "# classify using our pre-trained model\n",
    "predictions=dialect_classifier.predict(test_case_encoded_d)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"# return top 3 classes\\ntop_3 = np.argsort(predictions, axis=1)[:,-3:]\\nd['class_target'].inverse_transform(top_3[0].tolist())\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "\"\"\"# return top 3 classes\n",
    "top_3 = np.argsort(predictions, axis=1)[:,-3:]\n",
    "d['class_target'].inverse_transform(top_3[0].tolist())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['waltham Massachusetts', 'boston Massachusetts',\n",
       "       'norwalk Connecticut'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "d, d_classes, dialect_classifier, test_case=load_data()\n",
    "test_case_encoded = encode_data(test_case)\n",
    "predict_cities(test_case_encoded)\n",
    "# expected output = 'waltham Massachusetts', 'boston Massachusetts','norwalk Connecticut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Q01': array(['yinz', 'you', 'you all', 'you guys', 'you lot', 'you ’uns',\n",
       "        'yous', 'youse'], dtype=object),\n",
       " 'Q02': array(['doodle bug', 'millipede', 'pill bug', 'potato bug', 'roll-up bug',\n",
       "        'roly poly', 'sow bug', 'twiddle bug', 'wood louse'], dtype=object),\n",
       " 'Q03': array(['freeway', 'highway', 'parkway', 'turnpike'], dtype=object),\n",
       " 'Q04': array(['I have no word for this',\n",
       "        'I use lightning bug and firefly interchangeably', 'firefly',\n",
       "        'lightning bug', 'others', 'peenie wallie'], dtype=object),\n",
       " 'Q05': array(['cougar', 'mountain cat', 'mountain lion', 'panther', 'puma'],\n",
       "       dtype=object),\n",
       " 'Q06': array(['gym shoes', 'shoes', 'sneakersn'], dtype=object),\n",
       " 'Q07': array(['garage sale', 'rummage sale', 'tag sale', 'thrift sale',\n",
       "        'yard sale'], dtype=object),\n",
       " 'Q08': array(['Mary and merry are pronounced the same, but marry is different',\n",
       "        'all three are pronounced differently',\n",
       "        'all three are pronounced the same',\n",
       "        'merry and marry are pronounced the same, but Mary is different'],\n",
       "       dtype=object),\n",
       " 'Q09': array(['both', 'frosting', 'frosting and icing refer to different things',\n",
       "        'icing', 'neither', 'others'], dtype=object),\n",
       " 'Q10': array(['expressway', 'freeway', 'highway', 'parkway', 'turnpike'],\n",
       "       dtype=object),\n",
       " 'Q11': array(['gapers’ block', 'rubberneck', 'rubbernecking',\n",
       "        'rubbernecking is the activity (slowing down and gawking) that causes the traffic jam, but I have no word for the traffic jam itself'],\n",
       "       dtype=object),\n",
       " 'Q12': array(['different', 'same'], dtype=object),\n",
       " 'Q13': array(['bird', 'blow-off', 'crip course', 'crypt course', 'gut'],\n",
       "       dtype=object),\n",
       " 'Q14': array(['semi', 'semi-truck', 'tractor-trailer', 'trailer truck'],\n",
       "       dtype=object),\n",
       " 'Q15': array(['other', 'with the vowel in jam', 'with the vowel in palm'],\n",
       "       dtype=object),\n",
       " 'Q16': array(['coke', 'pop', 'soda', 'tonic'], dtype=object),\n",
       " 'Q17': array(['grinder', 'hoagie', 'sub'], dtype=object),\n",
       " 'Q18': array(['beer barn', 'bootlegger', 'brew thru', 'party barn'], dtype=object),\n",
       " 'Q19': array(['craw', 'crawfish', 'crayfish', 'crowfish'], dtype=object),\n",
       " 'Q20': array(['sunshower', 'the devil is beating his wife',\n",
       "        'the wolf is giving birth'], dtype=object),\n",
       " 'Q21': array(['rotary', 'roundabout'], dtype=object),\n",
       " 'Q22': array(['cabbage night', 'gate night', 'mischief night', 'trick night'],\n",
       "       dtype=object),\n",
       " 'Q23': array(['bubbler', 'drinking fountain', 'water bubbler'], dtype=object),\n",
       " 'Q24': array(['I use lightning bug and firefly interchangeably', 'firefly',\n",
       "        'lightning bug'], dtype=object),\n",
       " 'class_target': array(['abbot Maine', 'abington Massachusetts', 'acton Maine', ...,\n",
       "        'york Maine', 'york beach Maine', 'york harbor Maine'],\n",
       "       dtype=object)}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "d_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}