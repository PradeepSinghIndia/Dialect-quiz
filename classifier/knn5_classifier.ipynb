{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('venv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "092ed8abd312cbab0a98b75895a1e9c0250270ee5380f9df4b1b91829554bc4e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from joblib import dump,load\n",
    "import reverse_geocoder as rg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading question with text file for wrangling\n",
    "data=pd.read_csv(\"questions_with_text.csv\")\n",
    "data.drop(['city','ZIP','lat','Long'], axis=1, inplace=True)\n",
    "target_label=data.state\n",
    "features=data\n",
    "features.drop(['state','user_id'], axis=1, inplace=True)\n",
    "#features.head()\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Training:\n",
    "   . encode labels and save encoder.\n",
    "   . train a classifier to take text and return lat+Long\n",
    "# At inference time:\n",
    "   . take user input and return lat+Long    \n",
    "   . convert lat and Long to closest city by reverse_geocoder[for python3]\n",
    "      "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing points outside US\n",
    "#coordinate = (data['lat'][0], data['Long'][0])\n",
    "#rg.search(coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"def cc_from_coordinates(data,i):\\n    location_data=data.iloc[i,:]\\n    lat= location_data.lat\\n    lng= location_data.Long\\n    return (rg.search((lat,lng))[0].get('cc'))\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "\"\"\"def cc_from_coordinates(data,i):\n",
    "    location_data=data.iloc[i,:]\n",
    "    lat= location_data.lat\n",
    "    lng= location_data.Long\n",
    "    return (rg.search((lat,lng))[0].get('cc'))\n",
    "\"\"\"    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cc_from_coordinates(data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'country_info=[]\\nfor i,row in data.iterrows():\\n    country_info.append(cc_from_coordinates(row))\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# i tried filtering points based on whether or not \n",
    "# they're in US and find out search is a time botteneck\n",
    "# so i am using all points now\n",
    "\"\"\"country_info=[]\n",
    "for i,row in data.iterrows():\n",
    "    country_info.append(cc_from_coordinates(row))\n",
    "\"\"\"    "
   ]
  },
  {
   "source": [
    "## one hot encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features=pd.get_dummies(features)\n",
    "# in order to match with this our user responses \n",
    "# we will use align() function with a left join which requires dataset to\n",
    "# join to ,so we create a dataset of single row and delete it after align+join\n",
    "encoded_features.columns = encoded_features.columns.str.strip().str.lower().str.replace(' ', '_').str.replace(',', '')\n",
    "data_structure=encoded_features.head(1).copy()\n",
    "for col in data_structure.columns:\n",
    "    data_structure[col].values[:]=0\n",
    "data_structure.to_csv(\"empty_data_structure.csv\" ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X=encoded_features\n",
    "y=target_label\n",
    "X_train, X_test, y_train_state, y_test_state = train_test_split(X, y, test_size=0.05, random_state=42 ,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Vermont' 'Connecticut' 'Massachusetts' ... 'Massachusetts' 'Connecticut'\n 'Connecticut']\n"
     ]
    }
   ],
   "source": [
    "state_5nn = KNeighborsClassifier(n_neighbors=5)\n",
    "state_5nn.fit(X_train, y_train_state)\n",
    "print(state_5nn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['state_level_knn.joblib.dat']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "dump(state_5nn ,\"state_level_knn.joblib.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testmodel(model,x_test,y_test,n):\n",
    "    eval=model.predict(x_test[:n])==y_test[:n]\n",
    "    return (sum(eval)/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1625"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "testmodel(state_5nn,X_test,y_test_state,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "top 3 error 0.4409340659340659\n"
     ]
    }
   ],
   "source": [
    "pred_prob=state_5nn.predict_proba(X_test)\n",
    "# indexes of three highest probabilty classes\n",
    "top_3 = np.argsort(pred_prob, axis=1)[:,-3:]\n",
    "# top 3 errors\n",
    "y_test_copy=y_test_state.reset_index(drop=True)\n",
    "error_counts=0\n",
    "for index,value in y_test_copy.items():\n",
    "    current_results=[state_5nn.classes_[i] for i in top_3[index]]\n",
    "    error_counts+=y_test_state.iloc[index] in current_results\n",
    "print(\"top 3 error\" ,error_counts / y_test_state.shape[0])     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to get top3 answers from models\n",
    "def get_top_3(model,data):\n",
    "    pred_prob=state_5nn.predict_proba(data)\n",
    "    # indexes of three highest probabilty classes\n",
    "    top_3 = np.argsort(pred_prob, axis=1)[:,-3:]\n",
    "    results=[model.classes_[i] for i in top_3]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array(['New Hampshire', 'Puerto Rico', 'Vermont'], dtype=object)]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "get_top_3(model=state_5nn,data=X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_sample= pd.read_csv(\"empty_data_structure.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data=features.head(1).copy()\n",
    "sample_data.to_csv(\"sample_case_data.csv\" ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data= pd.read_csv(\"sample_case_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Q01                                   Q02  \\\n",
       "0  y’all  I have no idea what this creature is   \n",
       "\n",
       "                                                 Q03                      Q04  \\\n",
       "0  a freeway has limited access (no stop lights, ...  I have no word for this   \n",
       "\n",
       "       Q05                              Q06         Q07  \\\n",
       "0  painter  I have no general word for this  patio sale   \n",
       "\n",
       "                                                 Q08      Q09  \\\n",
       "0  Mary and marry are pronounced the same, but me...  neither   \n",
       "\n",
       "                                                 Q10  ...    Q15    Q16  \\\n",
       "0  a freeway has limited access (no stop lights, ...  ...  other  other   \n",
       "\n",
       "     Q17    Q18    Q19    Q20    Q21    Q22    Q23    Q24  \n",
       "0  other  other  other  other  other  other  other  other  \n",
       "\n",
       "[1 rows x 24 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Q01</th>\n      <th>Q02</th>\n      <th>Q03</th>\n      <th>Q04</th>\n      <th>Q05</th>\n      <th>Q06</th>\n      <th>Q07</th>\n      <th>Q08</th>\n      <th>Q09</th>\n      <th>Q10</th>\n      <th>...</th>\n      <th>Q15</th>\n      <th>Q16</th>\n      <th>Q17</th>\n      <th>Q18</th>\n      <th>Q19</th>\n      <th>Q20</th>\n      <th>Q21</th>\n      <th>Q22</th>\n      <th>Q23</th>\n      <th>Q24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>y’all</td>\n      <td>I have no idea what this creature is</td>\n      <td>a freeway has limited access (no stop lights, ...</td>\n      <td>I have no word for this</td>\n      <td>painter</td>\n      <td>I have no general word for this</td>\n      <td>patio sale</td>\n      <td>Mary and marry are pronounced the same, but me...</td>\n      <td>neither</td>\n      <td>a freeway has limited access (no stop lights, ...</td>\n      <td>...</td>\n      <td>other</td>\n      <td>other</td>\n      <td>other</td>\n      <td>other</td>\n      <td>other</td>\n      <td>other</td>\n      <td>other</td>\n      <td>other</td>\n      <td>other</td>\n      <td>other</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 24 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode it\n",
    "encoded_data = encoding_sample.align(pd.get_dummies(input_data),join = \"left\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoded_data[1].fillna(0)\n",
    "# convert na's to 0 (since we're one hot encoding)\n",
    "# encoded_data = encoded_data[1].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       q01_other  q01_yinz  q01_you  q01_you_all  q01_you_guys  q01_you_lot  \\\n",
       "count        1.0       1.0      1.0          1.0           1.0          1.0   \n",
       "mean         0.0       0.0      0.0          0.0           0.0          0.0   \n",
       "std          NaN       NaN      NaN          NaN           NaN          NaN   \n",
       "min          0.0       0.0      0.0          0.0           0.0          0.0   \n",
       "25%          0.0       0.0      0.0          0.0           0.0          0.0   \n",
       "50%          0.0       0.0      0.0          0.0           0.0          0.0   \n",
       "75%          0.0       0.0      0.0          0.0           0.0          0.0   \n",
       "max          0.0       0.0      0.0          0.0           0.0          0.0   \n",
       "\n",
       "       q01_you_’uns  q01_yous  q01_youse  q01_y’all  ...  \\\n",
       "count           1.0       1.0        1.0        1.0  ...   \n",
       "mean            0.0       0.0        0.0        0.0  ...   \n",
       "std             NaN       NaN        NaN        NaN  ...   \n",
       "min             0.0       0.0        0.0        0.0  ...   \n",
       "25%             0.0       0.0        0.0        0.0  ...   \n",
       "50%             0.0       0.0        0.0        0.0  ...   \n",
       "75%             0.0       0.0        0.0        0.0  ...   \n",
       "max             0.0       0.0        0.0        0.0  ...   \n",
       "\n",
       "       q23_drinking_fountain  q23_other  q23_water_bubbler  \\\n",
       "count                    1.0        1.0                1.0   \n",
       "mean                     0.0        0.0                0.0   \n",
       "std                      NaN        NaN                NaN   \n",
       "min                      0.0        0.0                0.0   \n",
       "25%                      0.0        0.0                0.0   \n",
       "50%                      0.0        0.0                0.0   \n",
       "75%                      0.0        0.0                0.0   \n",
       "max                      0.0        0.0                0.0   \n",
       "\n",
       "       q23_water_fountain  q24_i_have_no_word_for_this  \\\n",
       "count                 1.0                          1.0   \n",
       "mean                  0.0                          0.0   \n",
       "std                   NaN                          NaN   \n",
       "min                   0.0                          0.0   \n",
       "25%                   0.0                          0.0   \n",
       "50%                   0.0                          0.0   \n",
       "75%                   0.0                          0.0   \n",
       "max                   0.0                          0.0   \n",
       "\n",
       "       q24_i_use_lightning_bug_and_firefly_interchangeably  q24_firefly  \\\n",
       "count                                                1.0            1.0   \n",
       "mean                                                 0.0            0.0   \n",
       "std                                                  NaN            NaN   \n",
       "min                                                  0.0            0.0   \n",
       "25%                                                  0.0            0.0   \n",
       "50%                                                  0.0            0.0   \n",
       "75%                                                  0.0            0.0   \n",
       "max                                                  0.0            0.0   \n",
       "\n",
       "       q24_lightning_bug  q24_other  q24_peenie_wallie  \n",
       "count                1.0        1.0                1.0  \n",
       "mean                 0.0        0.0                0.0  \n",
       "std                  NaN        NaN                NaN  \n",
       "min                  0.0        0.0                0.0  \n",
       "25%                  0.0        0.0                0.0  \n",
       "50%                  0.0        0.0                0.0  \n",
       "75%                  0.0        0.0                0.0  \n",
       "max                  0.0        0.0                0.0  \n",
       "\n",
       "[8 rows x 197 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q01_other</th>\n      <th>q01_yinz</th>\n      <th>q01_you</th>\n      <th>q01_you_all</th>\n      <th>q01_you_guys</th>\n      <th>q01_you_lot</th>\n      <th>q01_you_’uns</th>\n      <th>q01_yous</th>\n      <th>q01_youse</th>\n      <th>q01_y’all</th>\n      <th>...</th>\n      <th>q23_drinking_fountain</th>\n      <th>q23_other</th>\n      <th>q23_water_bubbler</th>\n      <th>q23_water_fountain</th>\n      <th>q24_i_have_no_word_for_this</th>\n      <th>q24_i_use_lightning_bug_and_firefly_interchangeably</th>\n      <th>q24_firefly</th>\n      <th>q24_lightning_bug</th>\n      <th>q24_other</th>\n      <th>q24_peenie_wallie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 197 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "encoded_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_answers(input_data):\n",
    "    '''Reads in the sample encoded data w/ correct columns and \n",
    "    converts input data to the same format'''\n",
    "    # read in empty dataframe with correct columns\n",
    "    encoding_sample = pd.read_csv(\"empty_data_structure.csv\")\n",
    "\n",
    "    # encode it\n",
    "    encoded_data = encoding_sample.align(pd.get_dummies(input_data),\n",
    "    join = \"left\", axis = 1)\n",
    "\n",
    "    # convert na's to 0 (since we're one hot encoding)\n",
    "    encoded_data = encoded_data[1].fillna(0)\n",
    "    \n",
    "    return(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_3_knn(data):\n",
    "    '''Read in the knn model and apply it to correctly formatted sample data'''\n",
    "    # read in model\n",
    "    state_knn = load(\"state_level_knn.joblib.dat\")\n",
    "\n",
    "    # encode input data\n",
    "    encoded_data = encode_answers(data)\n",
    "\n",
    "    pred = state_knn.predict_proba(encoded_data)\n",
    "    top_3 = np.argsort(pred, axis=1)[ : ,-3 : ]\n",
    "    results = [state_knn.classes_[i] for i in top_3]\n",
    "\n",
    "    return(results[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text, Any, List, Union, Optional\n",
    "\n",
    "class ClassifierPipeline_knn():\n",
    "    \"\"\"Load in calssifier & encoders\"\"\"\n",
    "\n",
    "    def name(self) -> Text:\n",
    "        \"\"\"Unique identifier of the classfier \"\"\"\n",
    "\n",
    "        return \"5knn_state\"\n",
    "\n",
    "    def encode_answers(self, input_data):\n",
    "        '''Reads in the sample encoded data w/ correct columns and \n",
    "        converts input data to the same format'''\n",
    "        # read in empty dataframe with correct columns\n",
    "        encoding_sample = pd.read_csv(\"empty_data_structure.csv\")\n",
    "\n",
    "        # encode it\n",
    "        encoded_data = encoding_sample.align(pd.get_dummies(input_data),\n",
    "        join = \"left\", axis = 1)\n",
    "\n",
    "        # convert na's to 0 (since we're one hot encoding)\n",
    "        encoded_data = encoded_data[1].fillna(0)\n",
    "        \n",
    "        return(encoded_data)\n",
    "\n",
    "    def get_top_3_knn(self, data):\n",
    "        '''Read in the knn model and apply it to correctly formatted sample data'''\n",
    "        # read in model\n",
    "        state_knn = load(\"state_level_knn.joblib.dat\")\n",
    "\n",
    "        # encode input data\n",
    "        encoded_data = self.encode_answers(data)\n",
    "\n",
    "        pred = state_knn.predict_proba(encoded_data)\n",
    "        top_3 = np.argsort(pred, axis=1)[ : ,-3 : ]\n",
    "        results = [state_knn.classes_[i] for i in top_3]\n",
    "\n",
    "        return(results[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   q01_other  q01_yinz  q01_you  q01_you_all  q01_you_guys  q01_you_lot  \\\n",
       "0          0         0        0            0             0            0   \n",
       "\n",
       "   q01_you_’uns  q01_yous  q01_youse  q01_y’all  ...  q23_drinking_fountain  \\\n",
       "0             0         0          0          0  ...                      0   \n",
       "\n",
       "   q23_other  q23_water_bubbler  q23_water_fountain  \\\n",
       "0          0                  0                   0   \n",
       "\n",
       "   q24_i_have_no_word_for_this  \\\n",
       "0                            0   \n",
       "\n",
       "   q24_i_use_lightning_bug_and_firefly_interchangeably  q24_firefly  \\\n",
       "0                                                  0              0   \n",
       "\n",
       "   q24_lightning_bug  q24_other  q24_peenie_wallie  \n",
       "0                  0          0                  0  \n",
       "\n",
       "[1 rows x 197 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q01_other</th>\n      <th>q01_yinz</th>\n      <th>q01_you</th>\n      <th>q01_you_all</th>\n      <th>q01_you_guys</th>\n      <th>q01_you_lot</th>\n      <th>q01_you_’uns</th>\n      <th>q01_yous</th>\n      <th>q01_youse</th>\n      <th>q01_y’all</th>\n      <th>...</th>\n      <th>q23_drinking_fountain</th>\n      <th>q23_other</th>\n      <th>q23_water_bubbler</th>\n      <th>q23_water_fountain</th>\n      <th>q24_i_have_no_word_for_this</th>\n      <th>q24_i_use_lightning_bug_and_firefly_interchangeably</th>\n      <th>q24_firefly</th>\n      <th>q24_lightning_bug</th>\n      <th>q24_other</th>\n      <th>q24_peenie_wallie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 197 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "encode_answers(encoding_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_sample = pd.read_csv(\"empty_data_structure.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Maine', 'Massachusetts', 'Vermont']"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "get_top_3_knn(encoding_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Maine', 'Massachusetts', 'Vermont']"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "ClassifierPipeline_knn().get_top_3_knn(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data=features.head(2).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data=sample_data.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Maine', 'Massachusetts', 'Vermont']"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "ClassifierPipeline_knn().get_top_3_knn(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}